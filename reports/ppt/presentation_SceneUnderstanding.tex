\documentclass{beamer}
%\usetheme{Boadilla}
\usepackage[latin1]{inputenc}
\usepackage{ upgreek }
\usepackage{verbatim} 
\usepackage{amsmath}
\usepackage{wrapfig}

\usepackage{array}
\usepackage{amssymb}
\usepackage{graphicx}
\usepackage{url}
\usepackage{verbatim}
\usepackage{multirow} 
\usepackage{relsize}


\usepackage{cite}
\usepackage{url}
\usepackage{color}




\newlength\savedwidth
\newcommand\whline[1]{\noalign{\global\savedwidth\arrayrulewidth
                               \global\arrayrulewidth #1} %
                      \hline
                      \noalign{\global\arrayrulewidth\savedwidth}}
\renewcommand\multirowsetup{\centering}                  


\DeclareMathOperator*{\argmax}{argmax}
\DeclareMathOperator*{\argmin}{argmin}  

\usetheme{Warsaw}
\title{Contextually Guided Semantic Labeling and Search for 3D Pointclouds}
\author{Abhishek Anand, Hema Koppula }
\institute{Joint work with Thorsten Joachims and Ashutosh Saxena}






\newcommand{\n}{{n}}             % number of training examples
\newcommand{\x}{{\mathbf x}}     % segmented scene
\newcommand{\xs}[1]{{x_{#1}}}    % segment of scene
\newcommand{\y}{{\mathbf y}}     % labeling of scene
\newcommand{\ys}[1]{{y_{#1}}}    % labeling of segment
\newcommand{\ysc}[2]{{y_{#1}^{#2}}}    % indicator of class label of segment
\newcommand{\zsc}[2]{{z_{#1}^{#2}}}    % indicator of class label pair
\newcommand{\fn}[1]{{\phi_n(#1)}}      % feature function for segment node
\newcommand{\fe}[3]{{\phi_{#1}(#2,#3)}}% feature function for edge
\newcommand{\w}{{\mathbf w}}           % full weight vector
\newcommand{\wn}[1]{{w_n^{#1}}}        % weight vector of segment node
\newcommand{\we}[3]{{w_{#1}^{#2#3}}}   % weight vector of edge
\newcommand{\df}[3]{{f_{#3}(#1,#2)}}   % discriminant function
\newcommand{\loss}[2]{{\Delta(#1,#2)}}   % discriminant function

\newcommand{\wep}[3]{{w_{#1}'^{#2#3}}}   % weight vector of edge
\newcommand{\wnp}[1]{{w_n'^{#1}}}        % weight vector of segment node

\begin{document}
\begin{frame}
\titlepage
\end{frame}

\begin{frame}{Motivation}
Find objects : Wall, Table, Chair, Monitor, Keyboard, etc.
	\begin{figure}
		\includegraphics[width=0.65\linewidth]{scene2.png}
		\hskip0.1in
		\includegraphics[width=0.3\linewidth]{robot2.jpg}
	\end{figure}
\end{frame}

\begin{frame}{Previous Approaches}

	\begin{itemize}
		\item Most works used 2D images.
	\begin{itemize}
		\item Histogram Of image Gradients(Dalal2005)
		\item Using context to find objects(eg. Torralba2007)
		\item Part based models (eg. Pedro2008)

	\end{itemize}

		\item Some try to jointly infer 3D structure (eg. Hoeim2006,  Lee 2010, Vedau 2010).
	\end{itemize}

\end{frame}

\begin{frame}{Motivation}
	\begin{figure}[t!]
		\includegraphics[width=.5\linewidth]{kinect.jpg}
	\end{figure}

	\begin{itemize}
		\item 3D era for robots has arrived.
		\item Cheap, fast 3D machine vision.
		\item Both color and depth available.
	\end{itemize}

\end{frame}

\begin{frame}{Introduction}
	\begin{itemize}
		\item How does a Kinect pointcloud look like?
% \footnote{http://arstechnica.com/gaming/news/2010/11/bathed-in-light-how-the-kinect-paints-your-room-in-ir-video.ars}

	\end{itemize}
\end{frame}

\begin{frame}{Introduction}
	\begin{itemize}
		\item Desired goal: Labeled pointcloud

	\end{itemize}
\end{frame}

\begin{frame}{Approach}
	\begin{itemize}
		\item Obtain stitched pointclouds.
		\item Segment based on smoothness and continuity. 
		\begin{figure}
		       \includegraphics[width=.9\linewidth]{mengo.png}\\
		       \includegraphics[width=.9\linewidth]{meng_segmented.png}
	         \end{figure}
		\item Generate features and predict a label for each segment.
	\end{itemize}
	
	\vskip 0.25in
{\scriptsize
 H.Koppula, A.Anand, T.Joachims, and A.Saxena. \emph{Semantic Labeling of 3d point clouds for indoor scenes.} In NIPS, 2011.\\
 %H.Koppula, A.Anand, T.Joachims, and A.Saxena. \emph{Labeling 3d scenes for personal assistant robots. CoRR, abs/1106.5551, 2011.}
}
\end{frame}

\begin{frame}{Captured Properties}
	\begin{itemize}
		\item Visual Appearance
		\item  Local Shape and Geometry
		\item  Geometrical Context
	\end{itemize}

\end{frame}

\begin{frame}{Captured Properties}
        \begin{itemize}
                \item Visual Appearance
\begin{figure}[t!]
\includegraphics[width=.3\linewidth]{printer-small.png}
\hskip .2in
\includegraphics[width=.3\linewidth]{table-small.png}
\end{figure}
                \item  Local Shape and Geometry
                \item  Geometrical Context
        \end{itemize}

\end{frame}


\begin{frame}{Captured Properties}
        \begin{itemize}
                \item Visual Appearance
\begin{figure}[t!]
\includegraphics[width=.3\linewidth]{printer.jpg}
\hskip .2in
\includegraphics[width=.3\linewidth]{table.jpg}
\end{figure}
                \item  Local Shape and Geometry
                \item  Geometrical Context
        \end{itemize}

\end{frame}


\begin{frame}{Captured Properties}
        \begin{itemize}
                \item Visual Appearance
\begin{figure}[t!]
\includegraphics[width=.2\linewidth]{printer.jpg}
\hskip .2in
\includegraphics[width=.2\linewidth]{table.jpg}
\end{figure}

                \item  Local Shape and Geometry

		\begin{itemize}
			\item Table tops are horizontal.
			\item Table tops are at fixed heights.
			\item Faces of a printer form a convex shape.
		\end{itemize}

                \item  Geometrical Context
        \end{itemize}

\end{frame}



\begin{frame}{Geometrical Context}
\begin{figure}[t!]
\includegraphics[width=.8\linewidth]{contextHole.png}
\end{figure}
\end{frame}


\begin{frame}{Geometrical Context}
\begin{figure}[t!]
\includegraphics[width=.8\linewidth]{contextHoleFilled.png}
\end{figure}
\end{frame}

\begin{frame}{Captured Properties}
        \begin{itemize}
                \item Visual Appearance
\begin{figure}[t!]
\includegraphics[width=.1\linewidth]{printer.jpg}
\hskip .2in
\includegraphics[width=.1\linewidth]{table.jpg}
\end{figure}

                \item  Local Shape and Geometry

                \begin{itemize}
                        \item Table tops are horizontal.
                        \item Table tops are at fixed heights.
                        \item Faces of a printer form a convex shape.
                \end{itemize}

                \item  Geometrical Context
\begin{figure}[t!]
\includegraphics[width=.3\linewidth]{contextHole.png}
\hskip .2in
\includegraphics[width=.3\linewidth]{contextHoleFilled.png}
\end{figure}

        \end{itemize}

\end{frame}



\begin{frame}{Model}
\begin{itemize}
 \item The 3D scene is encoded using Markov Random Field  
  \item Each segment forms a node in the graph.
 \item Every segment is connected to its near-by segments with an edge.
 \item Log-linear node and pairwise edge potentials.
 % a small graph with objects in the scene representing nodes and edges?
\end{itemize}
\end{frame}

\begin{frame}{Model}
\begin{itemize}


\item Goal: Given a segmented point cloud $\x=(\xs{1},...,\xs{N})$  predict a labeling $\y=(\ys{1},...,\ys{N})$
\item Labels $\in  \{ 1, ..., K \} $
\item where $\ys{i}=(\ysc{i}{1},...,\ysc{i}{K})$,  $ \forall \ysc{i}{k} \in \{0,1\}$ 


\item For a segmented point cloud $\x$, the prediction $\hat{\y}$ is 
\begin{equation} \label{eq:argmax}
\hat{\y} = \argmax_\y \df{\x}{\y}{\w}
\end{equation}

\end{itemize}
\end{frame}


\begin{frame}{Model}
\begin{itemize}

\item Given $(\mathcal{V},\mathcal{E})$, individual segment features $\fn{i}$ and edge features $\fe{t}{i}{j}$

\begin{equation} \label{eq:model}
\begin{split}
\df{\y}{\x}{\w} & = \sum_{i \in \mathcal{V}} \sum_{k=1}^{K} \ysc{i}{k} \left[\wn{k} \cdot \fn{i} \right] \\
 & + \sum_{(i,j)\in \mathcal{E}}   \sum_{l=1}^{K}  \sum_{k=1}^{K} \ysc{i}{l} \ysc{j}{k}  \left[\we{t}{l}{k} \cdot \fe{t}{i}{j}\right] 
 \end{split}
\end{equation}

\end{itemize}
\end{frame}

\begin{frame}{Model}

\begin{itemize}
%There may be multiple types $t$ of edge feature maps $\fe{t}{i}{j}$, and each type has a graph over the $K$ classes with edges $T_t$. If $T_t$ contains an edge between classes $l$ and $k$, then this feature map and a weight vector $\we{t}{l}{k}$ is used to model the dependencies between classes $l$ and $k$. If the edge is not present in $T_t$, then $\fe{t}{i}{j}$ is not used.

\item Multiple types of edge feature maps.

\item Visual similarity between segments -- parts of the same object.
\item Vertical distance between segments -- relates different objects.

\end{itemize}
\begin{figure}[t!]
\includegraphics[width=.5\linewidth]{parsi.jpg}
\end{figure}



\end{frame}

\begin{frame}{Model}
\begin{itemize}

\item Each type has a graph over the $K$ classes with edges  $T_t$

\item Associative type:  ${T_t}=\{(k,k)| \forall k=1..K\}$
\item Non-associative type: $T_t=\{(l,k)| \forall l,k=1..K\}$
\item Object-associate type: $T_t=\{(l,k) | \exists object , ~ l,k\in {\rm parts}({\rm object})\}$
\end{itemize}
\hskip 1in
\begin{figure}
		\includegraphics[width=.8\linewidth]{objAssoc.png}
	\end{figure}


\end{frame}

\begin{frame}{Model}
Parsimonious Model


%\item Given $(\mathcal{V},\mathcal{E})$, individual segment features $\fn{i}$ and edge features $\fe{t}{i}{j}$

\begin{equation} \label{eq:model}
\begin{split}
\df{\y}{\x}{\w} & = \sum_{i \in \mathcal{V}} \sum_{k=1}^{K} \ysc{i}{k} \left[\wn{k} \cdot \fn{i} \right] \\
 & + \sum_{(i,j)\in \mathcal{E}}   \sum_{T_t \in {\cal T}}  \sum_{(l,k)\in T_t} \ysc{i}{l} \ysc{j}{k}  \left[\we{t}{l}{k} \cdot \fe{t}{i}{j}\right] 
 \end{split}
\end{equation}
\begin{itemize}
\item If $T_t$ contains edge $(l,k)$, then $\fe{t}{i}{j}$ and $\we{t}{l}{k}$  model the dependencies between classes $l$ and $k$.
\item Since $|T_{na}| >> |T_{oa}|$ , the number of parameters to learn is lesser compared to modeling all edges as non-associative.
%\item ``object-associative'' features $\fe{oa}{i}{j}$ - used between classes that are parts of the same object (e.g., ``chair base'', ``chair back'' and ``chair back rest''). 
%\item ``non-associative'' features $\fe{na}{i}{j}$ -  used between any pair of classes.

\end{itemize}
\end{frame}


\begin{frame}{Related Work on 3D data}

\begin{itemize}
\item Colored pointclouds (eg. Lai2010)
\item Uncolored pointclouds(eg. Xiong2010)
\end{itemize}
\end{frame}

\begin{frame}{Features}

\begin{itemize}
\item Node Features
\begin{itemize}
\item Visual Appearance
	\begin{itemize}
	\item Histogram of HSV color values
	\item Average HSV color values
	\item HOG features corresponding to the segment
	\end{itemize}
	\item Local Shape and Geometry
	\begin{itemize}
	\item Linear-ness , Planar-ness and Scatter
	\item Vertical component of the normal
	\item Vertical position of centroid
	\item Bounding box dimensions
	\item Distance from scene boundary
	\end{itemize}
\end{itemize}
\end{itemize}

\end{frame}

\begin{frame}{Features}

\begin{itemize}
\item Edge Features
\begin{itemize}
\item Visual Appearance
	\begin{itemize}
	\item Diff in avg. HSV color values
	\end{itemize}
	\item Local Shape and Geometry
	\begin{itemize}
	\item Coplanarity and convexity
	\end{itemize}
	\item Geometric context
	\begin{itemize}
	\item Horizontal distance b/w centroids
	\item Vertical displacement b/w centroids
	\item Angle between normals
	\item Diff in angle with vertical
	\item Distance between closest points
	\item Relative position from camera (in front of/ behind) 
	\end{itemize}
\end{itemize}
\end{itemize}

\end{frame}

\begin{frame}{Inference}
 \begin{eqnarray*}
\hat{\y}\!\!\!&=&\!\!\!\argmax_{\y} \sum_{i \in \mathcal{V}} \sum_{k=1}^{K} \ysc{i}{k} \left[\wn{k} \cdot \fn{i} \right] \\
&+&  \!\!\!\sum_{(i,j)\in \mathcal{E}}  \sum_{T_t \in {\cal T}} \sum_{(l,k)\in T_t} \ysc{i}{l} \ysc{j}{k}  \left[\we{t}{l}{k} \cdot \fe{t}{i}{j}\right] 
 \label{eq:relaxobj}\\
\end{eqnarray*}
\end{frame}

\begin{frame}{Inference}
 \begin{eqnarray*}
\hat{\y}\!\!\!&=&\!\!\!\argmax_{\y}\max_{\mathbf z} \sum_{i \in \mathcal{V}} \sum_{k=1}^{K} \ysc{i}{k} \left[\wn{k} \cdot \fn{i} \right] \\
&+&  \!\!\!\sum_{(i,j)\in \mathcal{E}}  \sum_{T_t \in {\cal T}} \sum_{(l,k)\in T_t} \zsc{ij}{lk} \left[\we{t}{l}{k} \cdot \fe{t}{i}{j}\right] 
 \label{eq:relaxobj}\\
\end{eqnarray*}
 \begin{eqnarray*}
  \forall i,j,l,k &:& \:\: \zsc{ij}{lk}\le \ysc{i}{l}, \:\:\:\:
\zsc{ij}{lk}\le \ysc{j}{k},\:\:\:\:
\ysc{i}{l} + \ysc{j}{k} \le \zsc{ij}{lk}+1,\:\:\:\: \\
\forall i &:& \sum_{j=1}^{K} y_i^j = 1\\
\forall i,j,l,k &:& \zsc{ij}{lk},\ysc{i}{l} \in \{ 0,1 \} \label{eq:relaxconst}
\end{eqnarray*}
\end{frame}

\begin{frame}{Learning using $SVM^{struct}$}

\begin{equation} \label{eq:model}
\begin{split}
\df{\y}{\x}{\w} & = \sum_{i \in \mathcal{V}} \sum_{k=1}^{K} \ysc{i}{k} \left[\wn{k} \cdot \fn{i} \right] \\
 & + \sum_{(i,j)\in \mathcal{E}}   \sum_{T_t \in {\cal T}}  \sum_{(l,k)\in T_t} \zsc{ij}{lk}   \left[\we{t}{l}{k} \cdot \fe{t}{i}{j}\right] \\
& = \w^T \Psi(\x,\y)
 \end{split}
\end{equation}
where, $\Psi(\x,\y)=XY$

\end{frame}

\begin{frame}{Learning using $SVM^{struct}$}
learn weights w such that $\w^T \Psi(\x,\y)$  is max for correct y
\begin{figure}[t!]
\includegraphics[width=.9\linewidth]{struct.png}
\end{figure}
\end{frame}


\begin{frame}{Learning using $SVM^{struct}$}
\begin{eqnarray} \label{eq:trainqp}
\min_{w,\xi}    \frac{1}{2} \w^T\w + C\xi\\
s.t.   \forall \bar{\y}_1,...,\bar{\y}_\n \in \{0,1\}^{N \cdot K} :\\
 \frac{1}{n} \w^T \sum_{i=1}^{n} [\Psi( \x_i, \y_i) \nonumber - \Psi(\x_i,\bar{\y}_i)] \ge \Delta(\y_i,\bar{\y}_i) -\xi \nonumber
\end{eqnarray}

\begin{itemize}
\item convex quadratic program
\item $2^{N.K}$ constraints!
\item cutting plane method
\item need to compute \\ $\bar{\y}_i  = \argmax_{\y \in \{0,1\}^{N \cdot K}} \left[ \w^T \Psi(\x_i,\y) + \loss{\y_i}{\y} \right]$
\end{itemize}
\end{frame}


\begin{frame}{Inference for Learning}
 \begin{eqnarray*}
\hat{\y}\!\!\!&=&\!\!\!\argmax_{\y}\max_{\mathbf z} \sum_{i \in \mathcal{V}} \sum_{k=1}^{K} \ysc{i}{k} \left[\wn{k} \cdot \fn{i} \right] \\
&+&  \!\!\!\sum_{(i,j)\in \mathcal{E}}  \sum_{T_t \in {\cal T}} \sum_{(l,k)\in T_t} \zsc{ij}{lk} \left[\we{t}{l}{k} \cdot \fe{t}{i}{j}\right] \\
&+& \color<0-1>{red}{\loss{\y_i}{\y}} \label{eq:relaxobj}\\
\end{eqnarray*} 

\begin{eqnarray*}
\forall i,j,l,k &:& \:\: \zsc{ij}{lk}\le \ysc{i}{l}, \:\:\:\:
\zsc{ij}{lk}\le \ysc{j}{k},\:\:\:\:
\ysc{i}{l} + \ysc{j}{k} \le \zsc{ij}{lk}+1,\:\:\:\: \\
\forall i,j,l,k &:& \zsc{ij}{lk},\ysc{i}{l} \in \{ 0,1 \} \label{eq:relaxconst}\\
\forall i &:& \sum_{j=1}^{K} y_i^j = 1\\
\end{eqnarray*} 

\end{frame}

\begin{frame}{Inference for Learning}
 \begin{eqnarray*}
\hat{\y}\!\!\!&=&\!\!\!\argmax_{\y}\max_{\mathbf z} \sum_{i \in \mathcal{V}} \sum_{k=1}^{K} \ysc{i}{k} \left[\wn{k} \cdot \fn{i} \right] \\
&+&  \!\!\!\sum_{(i,j)\in \mathcal{E}}  \sum_{T_t \in {\cal T}} \sum_{(l,k)\in T_t} \zsc{ij}{lk} \left[\we{t}{l}{k} \cdot \fe{t}{i}{j}\right] \\
&+& \loss{\y_i}{\y}
\end{eqnarray*}

\begin{eqnarray*}
\forall i,j,l,k &:& \:\: \zsc{ij}{lk}\le \ysc{i}{l}, \:\:\:\:
\zsc{ij}{lk}\le \ysc{j}{k},\:\:\:\:
\ysc{i}{l} + \ysc{j}{k} \le \zsc{ij}{lk}+1,\:\:\:\: \\
\forall i,j,l,k &:& \color<0-1>{red}{\zsc{ij}{lk},\ysc{i}{l} \in \{ 0,1 \}}\\
\forall i &:& \sum_{j=1}^{K} y_i^j = 1\\
\end{eqnarray*}

\end{frame}

\begin{frame}{Inference for Learning}
 \begin{eqnarray*}
\hat{\y}\!\!\!&=&\!\!\!\argmax_{\y}\max_{\mathbf z} \sum_{i \in \mathcal{V}} \sum_{k=1}^{K} \ysc{i}{k} \left[\wn{k} \cdot \fn{i} \right] \\
&+&  \!\!\!\sum_{(i,j)\in \mathcal{E}}  \sum_{T_t \in {\cal T}} \sum_{(l,k)\in T_t} \zsc{ij}{lk} \left[\we{t}{l}{k} \cdot \fe{t}{i}{j}\right] \\
&+& \loss{\y_i}{\y}
\end{eqnarray*}

\begin{eqnarray*}
\forall i,j,l,k &:& \:\: \zsc{ij}{lk}\le \ysc{i}{l}, \:\:\:\:
\zsc{ij}{lk}\le \ysc{j}{k},\:\:\:\:
\ysc{i}{l} + \ysc{j}{k} \le \zsc{ij}{lk}+1,\:\:\:\: \\
\forall i,j,l,k &:& \color<0-1>{red}{\zsc{ij}{lk},\ysc{i}{l} \in [ 0,1 ] }\\
\forall i &:& \sum_{j=1}^{K} y_i^j = 1\\
\end{eqnarray*}

\end{frame}

\begin{frame}{Inference for Learning}
 \begin{eqnarray*}
\hat{\y}\!\!\!&=&\!\!\!\argmax_{\y}\max_{\mathbf z} \sum_{i \in \mathcal{V}} \sum_{k=1}^{K} \ysc{i}{k} \left[\wn{k} \cdot \fn{i} \right] \\
&+&  \!\!\!\sum_{(i,j)\in \mathcal{E}}  \sum_{T_t \in {\cal T}} \sum_{(l,k)\in T_t} \zsc{ij}{lk} \left[\we{t}{l}{k} \cdot \fe{t}{i}{j}\right] \\
&+& \loss{\y_i}{\y}
\end{eqnarray*}

\begin{eqnarray*}
\forall i,j,l,k &:& \:\: \zsc{ij}{lk}\le \ysc{i}{l}, \:\:\:\:
\zsc{ij}{lk}\le \ysc{j}{k},\:\:\:\:
\ysc{i}{l} + \ysc{j}{k} \le \zsc{ij}{lk}+1,\:\:\:\: \\
\forall i,j,l,k &:& \zsc{ij}{lk},\ysc{i}{l} \in [ 0,1 ] \\
\forall i &:& \color<0-1>{red}{\sum_{j=1}^{K} y_i^j = 1}\\
\end{eqnarray*}

\end{frame}


\begin{frame}{Inference for Learning}
 \begin{eqnarray*}
\hat{\y}\!\!\!&=&\!\!\!\argmax_{\y}\max_{\mathbf z} \sum_{i \in \mathcal{V}} \sum_{k=1}^{K} \ysc{i}{k} \left[\wn{k} \cdot \fn{i} \right] \\
&+&  \!\!\!\sum_{(i,j)\in \mathcal{E}}  \sum_{T_t \in {\cal T}} \sum_{(l,k)\in T_t} \zsc{ij}{lk} \left[\we{t}{l}{k} \cdot \fe{t}{i}{j}\right] \\
&+& \loss{\y_i}{\y} \label{eq:relaxobj}\\
\forall i,j,l,k &:& \:\: \zsc{ij}{lk}\le \ysc{i}{l}, \:\:\:\:
\zsc{ij}{lk}\le \ysc{j}{k},\:\:\:\:
\ysc{i}{l} + \ysc{j}{k} \le \zsc{ij}{lk}+1,\:\:\:\: \\
\forall i,j,l,k &:& \zsc{ij}{lk},\ysc{i}{l} \in [ 0,1 ] \label{eq:relaxconst}
\end{eqnarray*} 

\begin{itemize}
 \item $y_i^k\in{0,0.5,1}$
 \item can be also solved by QBPO(which uses graph-cut)
\end{itemize}

\end{frame}


\begin{frame}{Data}
% types and number of scene 
% examples of labeled pointclouds
%Two types of indoor environments : 
	\begin{figure}
	\includegraphics[width=0.5\linewidth,height=0.75in]{office_scene.pdf}
	\includegraphics[width=0.5\linewidth,height=0.75in]{home_scene.pdf}
	\end{figure}

   \begin{itemize}
   \item Office 

   	\begin{itemize}
	\item 24 stitched scenes
	\item 1108 labeled segments
	\item {\scriptsize  \emph{wall, floor, tableTop, tableDrawer, tableLeg, chairBackRest, chairBase, chairBack, monitor, printerFront, printerSide keyboard, cpuTop, cpuFront, cpuSide, book, paper}}
	\end{itemize}



   \item Home
   	\begin{itemize}
   	\item  28 stitched scenes
	\item 1387 labeled segments
	\item {\scriptsize  \emph{wall, floor, tableTop, tableDrawer, tableLeg, chairBackRest, chairBase, sofaBase, sofaArm, sofaBackRest, bed, bedSide, quilt, pillow, shelfRack, laptop, book }}
	\end{itemize} 
\end{itemize}

\end{frame}

\begin{frame}{Results }
Results on 24 Office and 28 Home scenes for 17 classes each.
\begin{figure}[t!]
\includegraphics[width=\linewidth,height=1.5in]{results_table.pdf}
\end{figure}
\end{frame}


\begin{frame}{Results }

Results on 24 Office and 28 Home scenes for 17 classes each.
\begin{figure}[t!]
\includegraphics[width=\linewidth,height=1.5in]{results_table1.png}
\end{figure}
{\small
\begin{itemize}
\item Do image and point-cloud features capture complimentary information? 
\end{itemize}
}
\end{frame}

\begin{frame}{Results } 
Results on 24 Office and 28 Home scenes for 17 classes each.
\begin{figure}[t!]
\includegraphics[width=\linewidth,height=1.5in]{results_table2.png}
\end{figure}
{\small
\begin{itemize}
\item How	important	is context?
\end{itemize}
}
\end{frame}

\begin{frame}{Results}
Confusion Matrix for Office dataset
  \begin{figure}
		\includegraphics[scale=0.2]{objassoc_office_radius0_6.pdf} 
	\end{figure}

\end{frame}

\begin{frame}{Results}
Confusion Matrix for Home dataset
 \begin{figure}   
 \includegraphics[scale=0.2]{objassoc_home_radius0_6.pdf} 
 \end{figure}
\end{frame}



\begin{frame}{Putting it on the robot}

\begin{columns}
\column{.65\textwidth}
\begin{itemize}
\item The world has more than 17 classes.
\item What if an object is not found?
\end{itemize}
\column{.35\textwidth}
 \begin{figure}   
\includegraphics[width=\linewidth]{robot2.jpg}
 \end{figure}

\end{columns}

\end{frame}

\begin{frame}{What if an object in not found?}
\begin{center}
Where is the keyboard?
 \begin{figure}   
\includegraphics[width=0.9\linewidth]{contextorig.png}
 \end{figure}
 \end{center}
\end{frame}

\begin{frame}{What if an object in not found?}
\begin{itemize}
\item Find the most contextually likely location by imagining an segment at every discretized 3D location.
\end{itemize}
 \begin{figure}   
 \includegraphics[scale=0.3]{heatImage.png} 
 \end{figure}
\end{frame}

\begin{frame}{What if an object in not found?}
\begin{center}
Where is the keyboard?
 \begin{figure}   
\includegraphics[width=0.5\linewidth]{frontCropped.png}
\includegraphics[width=0.5\linewidth]{frontHeatCropped.png} \\
\includegraphics[width=0.5\linewidth]{topCropped.png}
\includegraphics[width=0.5\linewidth]{topHeatCropped.png} \\
 \end{figure}
 \end{center}
\end{frame}


\begin{frame}{Robotic Experiments}

% setup
%demo
% table of results
\begin{itemize}
\item Goal : Find a set of object classes in an office scene.
\item Start at a predetermined location and scan room. 
\item Classify pointclouds. 
\item Find contextually likely locations for the rest.
\item Update predicted locations when new objects are found.
\end{itemize}

\end{frame}

\begin{frame}{Robotic Experiments: Results}

\begin{itemize}

\item Results for finding 12 object classes in 10 office scenes

\end{itemize}

\begin {center}
{\footnotesize 
\begin{tabular}{c | c | c | c}
class & \# instances & precision & recall \\
\hline
Wall & 10 & 100 & 100 \\
Table Top & 10 & 100  &100  \\
Table Leg & 10 & 71.43 & 50  \\
Table Drawer & 7 & 100 & 71.43 \\
Chair Backrest & 10 & 100 & 100  \\
Chair Base & 10 & 100  & 100 \\
Chair Back & 8 & 100 & 87.5 \\
Monitor & 9  & 100 & 100 \\
Keyboard & 9 & 100 & 77.7 \\
CPU & 8 & 50 & 11.1 \\ 
Printer & 1 & 100 & 100 \\
Paper & 10 & 100 & 22.2 \\
\hline
Overall Micro & \multirow{2}{*}{102} & 96.15 & 75 \\
Overall Macro & & 93.45 & 76.66 \\

\end{tabular}
}
\end{center}

\end{frame}

\begin{frame}
\begin{center}
{\Huge 
Questions?
}
\end{center}
\end{frame}

\begin{frame}{Current Work: Using grammars for scene understanding}
current approach can't model:
\begin{itemize}
\item objects are typically composed of characteristic parts
\item higher level cues can help in segmentation
\item global shapes and sizes of segments
\item occlusion
\end{itemize}

\end{frame}


\begin{frame}{Current Work}
\begin{center}
{\huge
Object Affordance and Human Activity Recognition
}
\end{center}
\end{frame}

\begin{frame}{ Object Affordance and Human Activity Recognition}
\begin{itemize}
\item Affordances :  properties of the environment that afford a certain action to be performed by a human or an animal
\end{itemize}
\begin{figure}[t!]
\includegraphics[width=.95\linewidth]{affordances.pdf}
\end{figure}
\end{frame}

\begin{frame}{Object Affordance and Human Activity Recognition}
\begin{itemize}
\item Human-Object interactions: Affordance depends on human-poses / sub-actions
\end{itemize}
\begin{figure}[t!]
\includegraphics[width=.25\linewidth]{couch_sit.jpg}
\includegraphics[width=.25\linewidth]{couch_read.jpg}
\includegraphics[width=.25\linewidth]{couch_sleep.jpg}
\end{figure}
\begin{itemize}
\item Object-Object interactions: Affordance of objects are related
\end{itemize}
\begin{figure}[h]
\includegraphics[width=.25\linewidth]{pitcher-pouring.jpg}
\end{figure}
\end{frame}


\begin{frame}
\begin{center}
{\Huge 
Thank You!
}
\end{center}
\end{frame}

\begin{frame}{Results}
How large should the Context Range be?
  \begin{figure}
	\includegraphics[scale=0.5]{radiusEffectPlot.pdf} 
  \end{figure}
\end{frame}


\begin{frame}{The world has more than 17 classes}
 \begin{eqnarray*}
\hat{\y}\!\!\!&=&\!\!\!\argmax_{\y}\max_{\mathbf z} \sum_{i \in \mathcal{V}} \sum_{k=1}^{K} \ysc{i}{k} \left[\wn{k} \cdot \fn{i} \right] \\
&+&  \!\!\!\sum_{(i,j)\in \mathcal{E}}  \sum_{T_t \in {\cal T}} \sum_{(l,k)\in T_t} \zsc{ij}{lk} \left[\we{t}{l}{k} \cdot \fe{t}{i}{j}\right] \\
&+& \loss{\y_i}{\y} \label{eq:relaxobj}\\
\forall i,j,l,k &:& \:\: \zsc{ij}{lk}\le \ysc{i}{l}, \:\:\:\:
\zsc{ij}{lk}\le \ysc{j}{k},\:\:\:\:
\ysc{i}{l} + \ysc{j}{k} \le \zsc{ij}{lk}+1,\:\:\:\: \\
\forall i,j,l,k &:& \zsc{ij}{lk},\ysc{i}{l} \in [ 0,1 ] \label{eq:relaxconst}\\
\forall i &:& \sum_{j=1}^{K} y_i^j = 1
\end{eqnarray*} 

\end{frame}



\begin{frame}{The world has more than 17 classes}
 \begin{eqnarray*}
\hat{\y}\!\!\!&=&\!\!\!\argmax_{\y}\max_{\mathbf z} \sum_{i \in \mathcal{V}} \sum_{k=1}^{K} \ysc{i}{k} \left[\wn{k} \cdot \fn{i} \right] \\
&+&  \!\!\!\sum_{(i,j)\in \mathcal{E}}  \sum_{T_t \in {\cal T}} \sum_{(l,k)\in T_t} \zsc{ij}{lk} \left[\we{t}{l}{k} \cdot \fe{t}{i}{j}\right] \\
&+& \loss{\y_i}{\y} \label{eq:relaxobj}\\
\forall i,j,l,k &:& \:\: \zsc{ij}{lk}\le \ysc{i}{l}, \:\:\:\:
\zsc{ij}{lk}\le \ysc{j}{k},\:\:\:\:
\ysc{i}{l} + \ysc{j}{k} \le \zsc{ij}{lk}+1,\:\:\:\: \\
\forall i,j,l,k &:& \zsc{ij}{lk},\ysc{i}{l} \in [ 0,1 ] \label{eq:relaxconst} \\
\forall i &:& \sum_{j=1}^{K} y_i^j \le 1
\end{eqnarray*} 
\end{frame}


\begin{frame}{The world has more than 17 classes}
\begin{itemize}
\item Results on the two datasets using the above inference method:
\end{itemize}

\begin{center}
\begin{tabular}{c | c | c | c | c}
Data & Micro-  & Micro-  & Macro-  & Macro-\\
 &  precision &  recall &  precision &  recall\\
\hline
Office & 89.27 & 55.17 & 74.29 & 35.24 \\
Home & 82.09 & 52.35 & 52.03 & 26.22 \\
\hline
\end{tabular}
\end{center}
\end{frame}



\end{document} 
